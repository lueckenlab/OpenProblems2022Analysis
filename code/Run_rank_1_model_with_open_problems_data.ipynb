{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Rank 1 models with OpenProblems data fromat\n",
    "\n",
    "In this notebook, we will run rank 1 model with a dataset of OpenProblems data modality prediction task format. At 2022 competition, rank 1 model excelled in Multiome prediction task, so we'll focus on it. CITE-seq model leverages a lot of the same code and has a very similar architecture, so it should be possible to run it as well, just put CITE-seq data instead of Multiome in this tutorial and change task_type to \"cite\" in the scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from scanpy.preprocessing._utils import _get_mean_var\n",
    "import muon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download 2021 competition data from s3://openproblems-data/resources_test/task_predict_modality/openproblems_neurips2021/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna_train = sc.read_h5ad(\"../data/openproblems_neurips2021/bmmc_multiome/normal/train_mod1.h5ad\")\n",
    "adata_rna_test = sc.read_h5ad(\"../data/openproblems_neurips2021/bmmc_multiome/normal/test_mod1.h5ad\")\n",
    "adata_atac_train = sc.read_h5ad(\"../data/openproblems_neurips2021/bmmc_multiome/normal/train_mod2.h5ad\")\n",
    "adata_atac_test = sc.read_h5ad(\"../data/openproblems_neurips2021/bmmc_multiome/normal/test_mod2.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has both modalities, ATAC-seq and RNA in one AnnData object. Let's split modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((171, 1500), (427, 1500), (171, 1500), (427, 1500))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_rna_train.shape, adata_rna_test.shape, adata_atac_train.shape, adata_atac_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 500 × 116490\n",
       "    obs: 'GEX_pct_counts_mt', 'GEX_n_counts', 'GEX_n_genes', 'GEX_size_factors', 'GEX_phase', 'ATAC_nCount_peaks', 'ATAC_atac_fragments', 'ATAC_reads_in_peaks_frac', 'ATAC_blacklist_fraction', 'ATAC_nucleosome_signal', 'cell_type', 'batch', 'ATAC_pseudotime_order', 'GEX_pseudotime_order', 'Samplename', 'Site', 'DonorNumber', 'Modality', 'VendorLot', 'DonorID', 'DonorAge', 'DonorBMI', 'DonorBloodType', 'DonorRace', 'Ethnicity', 'DonorGender', 'QCMeds', 'DonorSmoker'\n",
       "    var: 'feature_types', 'gene_id'\n",
       "    uns: 'ATAC_gene_activity_var_names', 'dataset_id', 'genome', 'organism'\n",
       "    obsm: 'ATAC_gene_activity', 'ATAC_lsi_full', 'ATAC_lsi_red', 'ATAC_umap', 'GEX_X_pca', 'GEX_X_umap'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_atac = adata[:, adata.var[\"feature_types\"] == \"ATAC\"]\n",
    "adata_atac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's further reduce the number of features to 500 for RNA and 1000 for ATAC for faster testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_day_and_donor_from_batch(batch: str):\n",
    "    \"Extract day and donor numbers N and M from IDs of format sNdM\"\n",
    "    d_index = batch.find(\"d\")\n",
    "    day = batch[1: d_index]\n",
    "    donor = batch[d_index + 1 :]\n",
    "    return day, donor\n",
    "\n",
    "adata_rna_train.obs[\"day\"], adata_rna_train.obs[\"donor\"] = zip(*adata_rna_train.obs[\"batch\"].astype(str).map(extract_day_and_donor_from_batch))\n",
    "adata_rna_test.obs[\"day\"], adata_rna_test.obs[\"donor\"] = zip(*adata_rna_test.obs[\"batch\"].astype(str).map(extract_day_and_donor_from_batch))\n",
    "adata_atac_train.obs[\"day\"], adata_atac_train.obs[\"donor\"] = zip(*adata_atac_train.obs[\"batch\"].astype(str).map(extract_day_and_donor_from_batch))\n",
    "adata_atac_test.obs[\"day\"], adata_atac_test.obs[\"donor\"] = zip(*adata_atac_test.obs[\"batch\"].astype(str).map(extract_day_and_donor_from_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_factors</th>\n",
       "      <th>batch</th>\n",
       "      <th>day</th>\n",
       "      <th>donor</th>\n",
       "      <th>split</th>\n",
       "      <th>DonorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CGCCAAATCACCATTT-s2d4</th>\n",
       "      <td>241.0</td>\n",
       "      <td>s2d4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGTGTGGCACCTGCCT-4-s2d1</th>\n",
       "      <td>259.0</td>\n",
       "      <td>s2d1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGCCTGTGTATTCGCT-1-s1d1</th>\n",
       "      <td>165.0</td>\n",
       "      <td>s1d1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CACTGACCAGCTAACC-1-s1d1</th>\n",
       "      <td>157.0</td>\n",
       "      <td>s1d1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATGTGAGAGGCTGGCT-s2d4</th>\n",
       "      <td>95.0</td>\n",
       "      <td>s2d4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATTTAGCCACAACCTA-1-s1d1</th>\n",
       "      <td>281.0</td>\n",
       "      <td>s1d1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGTTGGCGTGCCGCAA-s2d4</th>\n",
       "      <td>89.0</td>\n",
       "      <td>s2d4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATGCAGGCAATTGACT-4-s2d1</th>\n",
       "      <td>240.0</td>\n",
       "      <td>s2d1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGTCAAGAGGTCCTAG-4-s2d1</th>\n",
       "      <td>225.0</td>\n",
       "      <td>s2d1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTAGCAAGTGAAGTG-4-s2d1</th>\n",
       "      <td>324.0</td>\n",
       "      <td>s2d1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         size_factors batch day donor  split DonorID\n",
       "CGCCAAATCACCATTT-s2d4           241.0  s2d4   2     4  train       4\n",
       "AGTGTGGCACCTGCCT-4-s2d1         259.0  s2d1   2     1  train       1\n",
       "CGCCTGTGTATTCGCT-1-s1d1         165.0  s1d1   1     1  train       1\n",
       "CACTGACCAGCTAACC-1-s1d1         157.0  s1d1   1     1  train       1\n",
       "ATGTGAGAGGCTGGCT-s2d4            95.0  s2d4   2     4  train       4\n",
       "...                               ...   ...  ..   ...    ...     ...\n",
       "ATTTAGCCACAACCTA-1-s1d1         281.0  s1d1   1     1  train       1\n",
       "AGTTGGCGTGCCGCAA-s2d4            89.0  s2d4   2     4  train       4\n",
       "ATGCAGGCAATTGACT-4-s2d1         240.0  s2d1   2     1  train       1\n",
       "AGTCAAGAGGTCCTAG-4-s2d1         225.0  s2d1   2     1  train       1\n",
       "TTTAGCAAGTGAAGTG-4-s2d1         324.0  s2d1   2     1  train       1\n",
       "\n",
       "[171 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_atac_train.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before modality prediction, apply QC to your dataset, otherwise the code will likely fail. Here, we'll simply remove cells with 0 RNA counts or open chromatin regions, and filter out constant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna_train.obs[\"split\"] = \"train\"\n",
    "adata_rna_test.obs[\"split\"] = \"test\"\n",
    "adata_atac_train.obs[\"split\"] = \"train\"\n",
    "adata_atac_test.obs[\"split\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna = sc.concat([adata_rna_train, adata_rna_test], axis=0)\n",
    "adata_atac = sc.concat([adata_atac_train, adata_atac_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put log-normalized data to `.X` layer of RNA and raw counts to `.X` of ATAC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna.X = adata_rna.layers[\"normalized\"]\n",
    "adata_atac.X = adata_atac.layers[\"counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_cells = (adata_rna.X.sum(axis=1) != 0) & (adata_atac.X.sum(axis=1) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna = adata_rna[non_empty_cells, :]\n",
    "adata_atac = adata_atac[non_empty_cells, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 1500)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna_means, rna_vars = _get_mean_var(adata_rna.X)\n",
    "adata_rna = adata_rna[:, rna_vars != 0]\n",
    "adata_rna.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 1500)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atac_means, atac_vars = _get_mean_var(adata_atac.X)\n",
    "adata_atac = adata_atac[:, atac_vars != 0]\n",
    "adata_atac.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize ATAC data with TF-IDF. Note that RNA data must be library-size and log1p normalized as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/muon/_atac/preproc.py:84: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , 14.8241296 ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 5.55391575,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muon.atac.pp.tfidf(adata_atac)\n",
    "adata_atac.X[:10, :10].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the data correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the model, we need to save our data to the following files:\n",
    "- test_multi_inputs.h5\n",
    "- train_multi_inputs.h5\n",
    "- train_multi_targets.h5\n",
    "\n",
    "If you want to use CITE-seq model too, the you'll additionally need:\n",
    "- test_cite_inputs\n",
    "- train_cite_inputs\n",
    "- train_cite_targets\n",
    "\n",
    "Additionally, we must save test set labels to the \"evaluation_ids.csv\" file with \"cell_id\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DonorID\n",
       "1     161\n",
       "8      94\n",
       "3      73\n",
       "2      62\n",
       "4      58\n",
       "10     55\n",
       "5      37\n",
       "9      37\n",
       "6      14\n",
       "7       7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_rna.obs[\"donor\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/anndata/_core/anndata.py:1230: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  df[key] = c\n"
     ]
    }
   ],
   "source": [
    "adata_rna[adata_rna.obs[\"split\"] == \"train\"].write_h5ad(\"../data/train_multi_targets.h5\")\n",
    "adata_atac[adata_atac.obs[\"split\"] == \"train\"].write_h5ad(\"../data/train_multi_inputs.h5\")\n",
    "adata_atac[adata_atac.obs[\"split\"] == \"test\"].write_h5ad(\"../data/test_multi_inputs.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to save metadata to a file. Note that in the current implementation, the metadata column **must** be named \"day\", \"donor\", \"technology\", \"cell_type\", and \"cell_id\". Day must be a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GEX_pct_counts_mt', 'GEX_n_counts', 'GEX_n_genes', 'GEX_size_factors',\n",
       "       'GEX_phase', 'ATAC_nCount_peaks', 'ATAC_atac_fragments',\n",
       "       'ATAC_reads_in_peaks_frac', 'ATAC_blacklist_fraction',\n",
       "       'ATAC_nucleosome_signal', 'cell_type', 'batch', 'ATAC_pseudotime_order',\n",
       "       'GEX_pseudotime_order', 'Samplename', 'Site', 'DonorNumber', 'Modality',\n",
       "       'VendorLot', 'DonorID', 'DonorAge', 'DonorBMI', 'DonorBloodType',\n",
       "       'DonorRace', 'Ethnicity', 'DonorGender', 'QCMeds', 'DonorSmoker',\n",
       "       'split'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_rna.obs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_factors</th>\n",
       "      <th>batch</th>\n",
       "      <th>day</th>\n",
       "      <th>donor</th>\n",
       "      <th>split</th>\n",
       "      <th>DonorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CGCCAAATCACCATTT-s2d4</th>\n",
       "      <td>241.0</td>\n",
       "      <td>s2d4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGTGTGGCACCTGCCT-4-s2d1</th>\n",
       "      <td>259.0</td>\n",
       "      <td>s2d1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGCCTGTGTATTCGCT-1-s1d1</th>\n",
       "      <td>165.0</td>\n",
       "      <td>s1d1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CACTGACCAGCTAACC-1-s1d1</th>\n",
       "      <td>157.0</td>\n",
       "      <td>s1d1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATGTGAGAGGCTGGCT-s2d4</th>\n",
       "      <td>95.0</td>\n",
       "      <td>s2d4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGTTTGTTCATCCTAT-2-s1d2</th>\n",
       "      <td>265.0</td>\n",
       "      <td>s1d2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCCTCACCATTATGAC-14-s3d10</th>\n",
       "      <td>460.0</td>\n",
       "      <td>s3d10</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACCTTAAGCCAAATC-14-s4d8</th>\n",
       "      <td>22.0</td>\n",
       "      <td>s4d8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCCAAATAGAACCTGT-14-s3d10</th>\n",
       "      <td>584.0</td>\n",
       "      <td>s3d10</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGGTGTTGTTTAACGG-13-s4d1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>s4d1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           size_factors  batch day donor  split DonorID\n",
       "CGCCAAATCACCATTT-s2d4             241.0   s2d4   2     4  train       4\n",
       "AGTGTGGCACCTGCCT-4-s2d1           259.0   s2d1   2     1  train       1\n",
       "CGCCTGTGTATTCGCT-1-s1d1           165.0   s1d1   1     1  train       1\n",
       "CACTGACCAGCTAACC-1-s1d1           157.0   s1d1   1     1  train       1\n",
       "ATGTGAGAGGCTGGCT-s2d4              95.0   s2d4   2     4  train       4\n",
       "...                                 ...    ...  ..   ...    ...     ...\n",
       "TGTTTGTTCATCCTAT-2-s1d2           265.0   s1d2   1     2   test       2\n",
       "CCCTCACCATTATGAC-14-s3d10         460.0  s3d10   3    10   test      10\n",
       "AACCTTAAGCCAAATC-14-s4d8           22.0   s4d8   4     8   test       8\n",
       "CCCAAATAGAACCTGT-14-s3d10         584.0  s3d10   3    10   test      10\n",
       "GGGTGTTGTTTAACGG-13-s4d1           40.0   s4d1   4     1   test       1\n",
       "\n",
       "[598 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_rna.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/74j47tdn36n6s2vcv_5079q0s4wk4h/T/ipykernel_83981/1730522646.py:1: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata_rna.obs[\"technology\"] = \"multiome\"\n"
     ]
    }
   ],
   "source": [
    "adata_rna.obs[\"technology\"] = \"multiome\"\n",
    "adata_rna.obs.index.name = \"cell_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna.obs[\"cell_type\"] = \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna.obs[[\"day\", \"donor\", \"technology\", \"cell_type\"]].reset_index(names=\"cell_id\").to_csv(\"../data/metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small function to save the data in the appropriate format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'train_multi_targets.h5'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'train_multi_inputs.h5'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/Users/vladimir.shitov/miniconda3/envs/2022_12_kaggle_ablation_study/lib/python3.8/site-packages/tables/path.py:137: NaturalNameWarning: object name is not a valid Python identifier: 'test_multi_inputs.h5'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    }
   ],
   "source": [
    "def save_X_to_h5(adata, path):\n",
    "    from pathlib import Path\n",
    "    path = Path(path)\n",
    "    X = adata.X.A if hasattr(adata.X, \"A\") else adata.X  # make dense if sparse\n",
    "    df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names).astype(np.float32)\n",
    "    df.to_hdf(\n",
    "        path,\n",
    "        key=path.name,  # e.g. \"train_multi_targets\"\n",
    "        mode=\"w\",\n",
    "        format=\"fixed\",\n",
    "    )\n",
    "\n",
    "save_X_to_h5(adata_rna[adata_rna.obs[\"split\"] == \"train\"], \"../data/train_multi_targets.h5\")\n",
    "save_X_to_h5(adata_atac[adata_atac.obs[\"split\"] == \"train\"], \"../data/train_multi_inputs.h5\")\n",
    "save_X_to_h5(adata_atac[adata_atac.obs[\"split\"] == \"test\"], \"../data/test_multi_inputs.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run scripts as recommended by competitor. For the given subset of data, it takes ~30 minutes on Macbook (cpu mode). If you wish to use CITE-seq model, change `task_type` to `cite` in the last script. You might also want to download additional files with biological priors for CITE-seq prediction. See [readme](https://github.com/lueckenlab/OpenProblems2022Analysis/tree/main/code/rank1/open-problems-multimodal) of the original repository for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/evaluation_ids.csv does not exist\n",
      "File /Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/sample_submission.csv does not exist\n",
      "427\n",
      "171\n",
      "171\n",
      "File /Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/test_cite_inputs.h5 does not exist\n",
      "File /Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/train_cite_inputs.h5 does not exist\n",
      "File /Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/train_cite_targets.h5 does not exist\n",
      "Some citeseq files don't exist, not making citeseq cell statistics\n",
      "File /Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/evaluation_ids.csv does not exist\n",
      "File /Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/sample_submission.csv does not exist\n",
      "427\n",
      "171\n",
      "171\n",
      "File /Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/test_cite_inputs.h5 does not exist\n",
      "File /Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/train_cite_inputs.h5 does not exist\n",
      "File /Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/train_cite_targets.h5 does not exist\n",
      "git_hexsha 3dd8d3456ff71f67b5643f66da72c92093dda632\n",
      "load input values\n",
      "completed loading input values. elapsed time: 0.0\n",
      "load targets values\n",
      "completed loading targets values. elapsed time: 0.0\n",
      "load input values\n",
      "completed loading input values. elapsed time: 0.0\n",
      "use test_inputs_values. total size: 598\n",
      "Changing upper quantile to 0.999\n",
      "train sample size: 171\n",
      "dump params\n",
      "use batch group. # groups is 4\n",
      "kfold type <class 'sklearn.model_selection._split.GroupKFold'> group [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "train group: [1 2 3]\n",
      "val group: [0]\n",
      "skip pre_post_process fit\n",
      "Changing upper quantile to 0.999\n",
      "model input shape X:(109, 256) Y:(109, 128)\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "dataset size 109\n",
      "start to train\n",
      "epoch: 0 total time: 8.2, epoch time: 8.1, loss: 10.333 loss_corr:-0.387 loss_mse: 9.722 loss_res_mse: 1.362 loss_total_corr:-0.364 \n",
      "epoch: 1 total time: 17.6, epoch time: 9.3, loss: 10.312 loss_corr:-0.389 loss_mse: 9.713 loss_res_mse: 1.355 loss_total_corr:-0.366 \n",
      "epoch: 2 total time: 26.1, epoch time: 8.4, loss: 10.340 loss_corr:-0.387 loss_mse: 9.730 loss_res_mse: 1.360 loss_total_corr:-0.363 \n",
      "epoch: 3 total time: 33.9, epoch time: 7.7, loss: 10.272 loss_corr:-0.390 loss_mse: 9.678 loss_res_mse: 1.351 loss_total_corr:-0.367 \n",
      "epoch: 4 total time: 42.3, epoch time: 8.2, loss: 10.252 loss_corr:-0.394 loss_mse: 9.672 loss_res_mse: 1.343 loss_total_corr:-0.370 \n",
      "epoch: 5 total time: 50.1, epoch time: 7.8, loss: 10.128 loss_corr:-0.398 loss_mse: 9.569 loss_res_mse: 1.331 loss_total_corr:-0.374 \n",
      "epoch: 6 total time: 58.1, epoch time: 7.9, loss: 10.091 loss_corr:-0.400 loss_mse: 9.541 loss_res_mse: 1.326 loss_total_corr:-0.375 \n",
      "epoch: 7 total time: 66.1, epoch time: 7.9, loss: 10.109 loss_corr:-0.398 loss_mse: 9.557 loss_res_mse: 1.324 loss_total_corr:-0.374 \n",
      "epoch: 8 total time: 74.8, epoch time: 8.6, loss: 9.888 loss_corr:-0.410 loss_mse: 9.387 loss_res_mse: 1.295 loss_total_corr:-0.384 \n",
      "epoch: 9 total time: 83.1, epoch time: 8.1, loss: 9.934 loss_corr:-0.405 loss_mse: 9.422 loss_res_mse: 1.297 loss_total_corr:-0.380 \n",
      "epoch: 10 total time: 91.5, epoch time: 8.3, loss: 9.504 loss_corr:-0.428 loss_mse: 9.090 loss_res_mse: 1.244 loss_total_corr:-0.401 \n",
      "epoch: 11 total time: 99.2, epoch time: 7.6, loss: 8.858 loss_corr:-0.429 loss_mse: 9.132 loss_res_mse: 1.235 loss_total_corr:-0.401 \n",
      "epoch: 12 total time: 107.3, epoch time: 8.1, loss: 8.059 loss_corr:-0.432 loss_mse: 8.991 loss_res_mse: 1.219 loss_total_corr:-0.404 \n",
      "epoch: 13 total time: 116.1, epoch time: 8.7, loss: 7.417 loss_corr:-0.432 loss_mse: 8.976 loss_res_mse: 1.212 loss_total_corr:-0.403 \n",
      "epoch: 14 total time: 124.7, epoch time: 8.4, loss: 6.720 loss_corr:-0.440 loss_mse: 8.891 loss_res_mse: 1.187 loss_total_corr:-0.410 \n",
      "epoch: 15 total time: 133.7, epoch time: 8.8, loss: 6.032 loss_corr:-0.447 loss_mse: 8.760 loss_res_mse: 1.168 loss_total_corr:-0.416 \n",
      "epoch: 16 total time: 142.6, epoch time: 8.9, loss: 5.401 loss_corr:-0.455 loss_mse: 8.672 loss_res_mse: 1.141 loss_total_corr:-0.425 \n",
      "epoch: 17 total time: 151.2, epoch time: 8.4, loss: 4.781 loss_corr:-0.461 loss_mse: 8.522 loss_res_mse: 1.126 loss_total_corr:-0.429 \n",
      "epoch: 18 total time: 160.1, epoch time: 8.8, loss: 4.238 loss_corr:-0.468 loss_mse: 8.457 loss_res_mse: 1.106 loss_total_corr:-0.437 \n",
      "epoch: 19 total time: 168.3, epoch time: 8.1, loss: 3.851 loss_corr:-0.460 loss_mse: 8.553 loss_res_mse: 1.118 loss_total_corr:-0.427 \n",
      "epoch: 20 total time: 176.0, epoch time: 7.7, loss: 3.387 loss_corr:-0.464 loss_mse: 8.531 loss_res_mse: 1.106 loss_total_corr:-0.432 \n",
      "epoch: 21 total time: 183.8, epoch time: 7.7, loss: 2.945 loss_corr:-0.468 loss_mse: 8.493 loss_res_mse: 1.097 loss_total_corr:-0.435 \n",
      "epoch: 22 total time: 192.6, epoch time: 8.7, loss: 2.473 loss_corr:-0.478 loss_mse: 8.363 loss_res_mse: 1.073 loss_total_corr:-0.446 \n",
      "epoch: 23 total time: 200.8, epoch time: 8.1, loss: 2.042 loss_corr:-0.485 loss_mse: 8.221 loss_res_mse: 1.060 loss_total_corr:-0.454 \n",
      "epoch: 24 total time: 208.7, epoch time: 7.8, loss: 1.732 loss_corr:-0.480 loss_mse: 8.280 loss_res_mse: 1.070 loss_total_corr:-0.448 \n",
      "epoch: 25 total time: 216.4, epoch time: 7.6, loss: 1.464 loss_corr:-0.473 loss_mse: 8.434 loss_res_mse: 1.077 loss_total_corr:-0.441 \n",
      "epoch: 26 total time: 224.0, epoch time: 7.6, loss: 1.044 loss_corr:-0.490 loss_mse: 8.105 loss_res_mse: 1.047 loss_total_corr:-0.459 \n",
      "epoch: 27 total time: 231.9, epoch time: 7.8, loss: 0.806 loss_corr:-0.484 loss_mse: 8.230 loss_res_mse: 1.055 loss_total_corr:-0.453 \n",
      "epoch: 28 total time: 240.1, epoch time: 8.1, loss: 0.557 loss_corr:-0.483 loss_mse: 8.266 loss_res_mse: 1.056 loss_total_corr:-0.452 \n",
      "epoch: 29 total time: 247.7, epoch time: 7.5, loss: 0.295 loss_corr:-0.488 loss_mse: 8.187 loss_res_mse: 1.046 loss_total_corr:-0.458 \n",
      "epoch: 30 total time: 255.8, epoch time: 7.9, loss: 0.092 loss_corr:-0.486 loss_mse: 8.244 loss_res_mse: 1.054 loss_total_corr:-0.455 \n",
      "epoch: 31 total time: 263.5, epoch time: 7.7, loss:-0.099 loss_corr:-0.483 loss_mse: 8.248 loss_res_mse: 1.054 loss_total_corr:-0.453 \n",
      "epoch: 32 total time: 271.7, epoch time: 8.1, loss:-0.320 loss_corr:-0.498 loss_mse: 8.061 loss_res_mse: 1.031 loss_total_corr:-0.468 \n",
      "epoch: 33 total time: 280.5, epoch time: 8.7, loss:-0.439 loss_corr:-0.486 loss_mse: 8.221 loss_res_mse: 1.049 loss_total_corr:-0.457 \n",
      "epoch: 34 total time: 289.7, epoch time: 9.0, loss:-0.570 loss_corr:-0.485 loss_mse: 8.257 loss_res_mse: 1.051 loss_total_corr:-0.458 \n",
      "epoch: 35 total time: 301.7, epoch time: 11.8, loss:-0.685 loss_corr:-0.485 loss_mse: 8.213 loss_res_mse: 1.052 loss_total_corr:-0.458 \n",
      "epoch: 36 total time: 311.2, epoch time: 9.5, loss:-0.782 loss_corr:-0.487 loss_mse: 8.187 loss_res_mse: 1.045 loss_total_corr:-0.459 \n",
      "epoch: 37 total time: 320.3, epoch time: 9.0, loss:-0.855 loss_corr:-0.488 loss_mse: 8.241 loss_res_mse: 1.045 loss_total_corr:-0.460 \n",
      "epoch: 38 total time: 329.3, epoch time: 8.8, loss:-0.929 loss_corr:-0.499 loss_mse: 7.963 loss_res_mse: 1.026 loss_total_corr:-0.471 \n",
      "epoch: 39 total time: 338.3, epoch time: 8.9, loss:-0.946 loss_corr:-0.492 loss_mse: 8.162 loss_res_mse: 1.039 loss_total_corr:-0.464 \n",
      "completed training\n",
      "model parameter summary:\n",
      "\ty_loc:\t\t\t8.4788e-02 +- 1.0215e+00. max=1.1394e+01 min=-6.5819e-01\n",
      "\ty_scale:\t\t\t2.7945e+00 +- 8.9587e-01. max=7.3315e+00 min=1.5745e+00\n",
      "\tinputs_decomposer_components:\t\t\t1.9875e-04 +- 2.5819e-02. max=1.4777e-01 min=-1.5526e-01\n",
      "\ttargets_decomposer_components:\t\t\t4.0042e-04 +- 2.5817e-02. max=3.3770e-01 min=-2.5994e-01\n",
      "\ttargets_global_median:\t\t\t-2.0457e-01 +- 4.3035e-01. max=5.7632e+00 min=-3.5212e-01\n",
      "\tgender_embedding:\t\t\t5.0684e-01 +- 2.8632e-01. max=9.9888e-01 min=2.7311e-04\n",
      "\tencoder.layers.0.fc.weight:\t\t\t-6.7405e-06 +- 1.2759e-02. max=2.3235e-02 min=-2.3253e-02\n",
      "\tencoder.layers.0.norm.weight:\t\t\t1.0000e+00 +- 3.9773e-04. max=1.0013e+00 min=9.9876e-01\n",
      "\tencoder.layers.0.norm.bias:\t\t\t-6.9386e-07 +- 3.1288e-04. max=9.6175e-04 min=-1.0192e-03\n",
      "\tencoder.out_fc.weight:\t\t\t-4.5399e-06 +- 1.2764e-02. max=2.3250e-02 min=-2.3302e-02\n",
      "\tencoder.out_fc.bias:\t\t\t1.6103e-04 +- 1.2843e-02. max=2.2376e-02 min=-2.2142e-02\n",
      "\tdecoder.in_fc.weight:\t\t\t4.0959e-06 +- 1.2760e-02. max=2.3286e-02 min=-2.3288e-02\n",
      "\tdecoder.in_fc.bias:\t\t\t3.2206e-04 +- 1.2674e-02. max=2.2429e-02 min=-2.2338e-02\n",
      "\tdecoder.layers.0.fc.weight:\t\t\t-5.4433e-06 +- 1.2754e-02. max=2.3323e-02 min=-2.3299e-02\n",
      "\tdecoder.layers.0.norm.weight:\t\t\t9.9981e-01 +- 3.4045e-04. max=1.0012e+00 min=9.9888e-01\n",
      "\tdecoder.layers.0.norm.bias:\t\t\t2.7075e-06 +- 2.6075e-04. max=8.8280e-04 min=-8.3119e-04\n",
      "\tdecoder.layers.1.fc.weight:\t\t\t-5.6297e-06 +- 1.2756e-02. max=2.3259e-02 min=-2.3206e-02\n",
      "\tdecoder.layers.1.norm.weight:\t\t\t9.9973e-01 +- 3.3717e-04. max=1.0008e+00 min=9.9881e-01\n",
      "\tdecoder.layers.1.norm.bias:\t\t\t-1.4416e-07 +- 2.9766e-04. max=8.5763e-04 min=-1.0466e-03\n",
      "\tdecoder.layers.2.fc.weight:\t\t\t7.9858e-06 +- 1.2749e-02. max=2.3279e-02 min=-2.3372e-02\n",
      "\tdecoder.layers.2.norm.weight:\t\t\t9.9962e-01 +- 3.2497e-04. max=1.0009e+00 min=9.9871e-01\n",
      "\tdecoder.layers.2.norm.bias:\t\t\t-5.7469e-06 +- 3.1786e-04. max=9.3245e-04 min=-9.5300e-04\n",
      "\tdecoder.layers.3.fc.weight:\t\t\t-3.8158e-06 +- 1.2749e-02. max=2.3316e-02 min=-2.3217e-02\n",
      "\tdecoder.layers.3.norm.weight:\t\t\t9.9950e-01 +- 3.0822e-04. max=1.0008e+00 min=9.9866e-01\n",
      "\tdecoder.layers.3.norm.bias:\t\t\t6.0885e-06 +- 3.3423e-04. max=9.6185e-04 min=-1.0848e-03\n",
      "\tdecoder.layers.4.fc.weight:\t\t\t-1.2163e-06 +- 1.2741e-02. max=2.3224e-02 min=-2.3146e-02\n",
      "\tdecoder.layers.4.norm.weight:\t\t\t9.9926e-01 +- 2.6174e-04. max=1.0003e+00 min=9.9848e-01\n",
      "\tdecoder.layers.4.norm.bias:\t\t\t-1.2407e-05 +- 3.4888e-04. max=1.0392e-03 min=-1.0296e-03\n",
      "\tencoder_in_fc.weight:\t\t\t1.0849e-05 +- 3.5614e-02. max=6.2810e-02 min=-6.2797e-02\n",
      "\tencoder_in_fc.bias:\t\t\t-9.0356e-04 +- 3.4931e-02. max=6.2201e-02 min=-6.1755e-02\n",
      "\tdecoder_out_fcs.0.weight:\t\t\t-5.0543e-06 +- 1.2762e-02. max=2.3513e-02 min=-2.3498e-02\n",
      "\tdecoder_out_fcs.0.bias:\t\t\t-1.1239e-03 +- 1.3064e-02. max=2.2609e-02 min=-2.2023e-02\n",
      "\tdecoder_out_fcs.1.weight:\t\t\t-9.9599e-06 +- 1.2713e-02. max=2.3248e-02 min=-2.3339e-02\n",
      "\tdecoder_out_fcs.1.bias:\t\t\t-4.9205e-04 +- 1.3223e-02. max=2.1803e-02 min=-2.1966e-02\n",
      "\tdecoder_out_fcs.2.weight:\t\t\t1.7321e-05 +- 1.2711e-02. max=2.3293e-02 min=-2.3440e-02\n",
      "\tdecoder_out_fcs.2.bias:\t\t\t-4.1473e-04 +- 1.1919e-02. max=2.1240e-02 min=-2.1859e-02\n",
      "\tdecoder_out_fcs.3.weight:\t\t\t1.0755e-05 +- 1.2698e-02. max=2.3141e-02 min=-2.3125e-02\n",
      "\tdecoder_out_fcs.3.bias:\t\t\t7.7655e-04 +- 1.2940e-02. max=2.2067e-02 min=-2.0888e-02\n",
      "\tdecoder_out_fcs.4.weight:\t\t\t3.5869e-05 +- 1.2685e-02. max=2.3107e-02 min=-2.3197e-02\n",
      "\tdecoder_out_fcs.4.bias:\t\t\t-7.0554e-04 +- 1.2281e-02. max=2.0785e-02 min=-2.2580e-02\n",
      "\tdecoder_out_fcs.5.weight:\t\t\t-3.6400e-05 +- 1.2672e-02. max=2.2939e-02 min=-2.2906e-02\n",
      "\tdecoder_out_fcs.5.bias:\t\t\t-2.2549e-04 +- 1.2858e-02. max=2.1651e-02 min=-2.2608e-02\n",
      "\tdecoder_out_res_fcs.0.weight:\t\t\t-7.4371e-06 +- 1.2750e-02. max=2.4033e-02 min=-2.4044e-02\n",
      "\tdecoder_out_res_fcs.0.bias:\t\t\t3.8981e-04 +- 1.2809e-02. max=2.3317e-02 min=-2.3385e-02\n",
      "\tdecoder_out_res_fcs.1.weight:\t\t\t4.9762e-06 +- 1.2703e-02. max=2.3807e-02 min=-2.3740e-02\n",
      "\tdecoder_out_res_fcs.1.bias:\t\t\t3.6912e-04 +- 1.2622e-02. max=2.3522e-02 min=-2.3301e-02\n",
      "\tdecoder_out_res_fcs.2.weight:\t\t\t-9.4797e-08 +- 1.2684e-02. max=2.3833e-02 min=-2.3641e-02\n",
      "\tdecoder_out_res_fcs.2.bias:\t\t\t-4.4029e-04 +- 1.2710e-02. max=2.3284e-02 min=-2.2724e-02\n",
      "\tdecoder_out_res_fcs.3.weight:\t\t\t-4.1967e-06 +- 1.2672e-02. max=2.3981e-02 min=-2.3771e-02\n",
      "\tdecoder_out_res_fcs.3.bias:\t\t\t-1.2214e-04 +- 1.2585e-02. max=2.2835e-02 min=-2.2616e-02\n",
      "\tdecoder_out_res_fcs.4.weight:\t\t\t1.1159e-06 +- 1.2671e-02. max=2.3658e-02 min=-2.3690e-02\n",
      "\tdecoder_out_res_fcs.4.bias:\t\t\t1.5175e-04 +- 1.2874e-02. max=2.3408e-02 min=-2.3006e-02\n",
      "\tdecoder_out_res_fcs.5.weight:\t\t\t1.3821e-05 +- 1.2662e-02. max=2.3569e-02 min=-2.3627e-02\n",
      "\tdecoder_out_res_fcs.5.bias:\t\t\t8.6326e-04 +- 1.3103e-02. max=2.3445e-02 min=-2.2766e-02\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "Fold 0 bagging 0 mse_train:  1.20147 corrscore_train:  0.56022 mse_val:  1.41150 corrscore_val:  0.43796 \n",
      "Fold 0: score:{'mse_train': 1.2014694, 'corrscore_train': 0.5602160571557264, 'unknown_mse_train': 1.2014694, 'unknown_corrscore_train': 0.5602160571557264, 'mse_val': 1.4115047, 'corrscore_val': 0.43795963284476225, 'unknown_mse_val': 1.4115047, 'unknown_corrscore_val': 0.43795963284476225} elapsed time =  347.907\n",
      "train group: [0 2 3]\n",
      "val group: [1]\n",
      "skip pre_post_process fit\n",
      "Changing upper quantile to 0.999\n",
      "model input shape X:(113, 256) Y:(113, 128)\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "dataset size 113\n",
      "start to train\n",
      "epoch: 0 total time: 9.1, epoch time: 9.0, loss: 10.494 loss_corr:-0.376 loss_mse: 9.840 loss_res_mse: 1.383 loss_total_corr:-0.354 \n",
      "epoch: 1 total time: 17.8, epoch time: 8.6, loss: 10.345 loss_corr:-0.384 loss_mse: 9.723 loss_res_mse: 1.367 loss_total_corr:-0.361 \n",
      "epoch: 2 total time: 27.0, epoch time: 9.1, loss: 10.294 loss_corr:-0.382 loss_mse: 9.664 loss_res_mse: 1.371 loss_total_corr:-0.359 \n",
      "epoch: 3 total time: 41.3, epoch time: 14.1, loss: 10.429 loss_corr:-0.380 loss_mse: 9.791 loss_res_mse: 1.375 loss_total_corr:-0.356 \n",
      "epoch: 4 total time: 49.4, epoch time: 8.0, loss: 10.233 loss_corr:-0.391 loss_mse: 9.640 loss_res_mse: 1.351 loss_total_corr:-0.367 \n",
      "epoch: 5 total time: 57.6, epoch time: 8.1, loss: 10.222 loss_corr:-0.390 loss_mse: 9.629 loss_res_mse: 1.349 loss_total_corr:-0.366 \n",
      "epoch: 6 total time: 66.5, epoch time: 8.7, loss: 10.074 loss_corr:-0.395 loss_mse: 9.507 loss_res_mse: 1.333 loss_total_corr:-0.371 \n",
      "epoch: 7 total time: 74.6, epoch time: 8.0, loss: 10.022 loss_corr:-0.399 loss_mse: 9.471 loss_res_mse: 1.324 loss_total_corr:-0.374 \n",
      "epoch: 8 total time: 82.6, epoch time: 8.0, loss: 10.032 loss_corr:-0.395 loss_mse: 9.475 loss_res_mse: 1.324 loss_total_corr:-0.371 \n",
      "epoch: 9 total time: 90.8, epoch time: 8.1, loss: 9.857 loss_corr:-0.405 loss_mse: 9.340 loss_res_mse: 1.301 loss_total_corr:-0.379 \n",
      "epoch: 10 total time: 98.7, epoch time: 7.8, loss: 9.665 loss_corr:-0.416 loss_mse: 9.201 loss_res_mse: 1.269 loss_total_corr:-0.390 \n",
      "epoch: 11 total time: 106.7, epoch time: 7.9, loss: 8.890 loss_corr:-0.419 loss_mse: 9.130 loss_res_mse: 1.253 loss_total_corr:-0.392 \n",
      "epoch: 12 total time: 114.5, epoch time: 7.7, loss: 8.110 loss_corr:-0.425 loss_mse: 9.016 loss_res_mse: 1.236 loss_total_corr:-0.396 \n",
      "epoch: 13 total time: 122.3, epoch time: 7.7, loss: 7.349 loss_corr:-0.432 loss_mse: 8.892 loss_res_mse: 1.211 loss_total_corr:-0.402 \n",
      "epoch: 14 total time: 130.4, epoch time: 8.0, loss: 6.754 loss_corr:-0.434 loss_mse: 8.910 loss_res_mse: 1.198 loss_total_corr:-0.404 \n",
      "epoch: 15 total time: 138.9, epoch time: 8.4, loss: 5.992 loss_corr:-0.447 loss_mse: 8.701 loss_res_mse: 1.168 loss_total_corr:-0.414 \n",
      "epoch: 16 total time: 147.4, epoch time: 8.5, loss: 5.432 loss_corr:-0.448 loss_mse: 8.683 loss_res_mse: 1.156 loss_total_corr:-0.417 \n",
      "epoch: 17 total time: 157.8, epoch time: 10.3, loss: 4.828 loss_corr:-0.457 loss_mse: 8.576 loss_res_mse: 1.136 loss_total_corr:-0.424 \n",
      "epoch: 18 total time: 166.6, epoch time: 8.7, loss: 4.297 loss_corr:-0.460 loss_mse: 8.518 loss_res_mse: 1.123 loss_total_corr:-0.427 \n",
      "epoch: 19 total time: 174.6, epoch time: 8.0, loss: 3.780 loss_corr:-0.465 loss_mse: 8.434 loss_res_mse: 1.111 loss_total_corr:-0.432 \n",
      "epoch: 20 total time: 182.6, epoch time: 7.9, loss: 3.357 loss_corr:-0.464 loss_mse: 8.466 loss_res_mse: 1.105 loss_total_corr:-0.433 \n",
      "epoch: 21 total time: 191.4, epoch time: 8.7, loss: 2.955 loss_corr:-0.464 loss_mse: 8.499 loss_res_mse: 1.103 loss_total_corr:-0.433 \n",
      "epoch: 22 total time: 199.5, epoch time: 8.0, loss: 2.447 loss_corr:-0.475 loss_mse: 8.259 loss_res_mse: 1.084 loss_total_corr:-0.442 \n",
      "epoch: 23 total time: 207.5, epoch time: 7.9, loss: 2.104 loss_corr:-0.470 loss_mse: 8.288 loss_res_mse: 1.090 loss_total_corr:-0.438 \n",
      "epoch: 24 total time: 215.3, epoch time: 7.8, loss: 1.716 loss_corr:-0.477 loss_mse: 8.194 loss_res_mse: 1.077 loss_total_corr:-0.445 \n",
      "epoch: 25 total time: 223.1, epoch time: 7.7, loss: 1.465 loss_corr:-0.465 loss_mse: 8.364 loss_res_mse: 1.095 loss_total_corr:-0.434 \n",
      "epoch: 26 total time: 230.9, epoch time: 7.8, loss: 1.113 loss_corr:-0.476 loss_mse: 8.256 loss_res_mse: 1.078 loss_total_corr:-0.444 \n",
      "epoch: 27 total time: 239.9, epoch time: 8.9, loss: 0.776 loss_corr:-0.487 loss_mse: 8.107 loss_res_mse: 1.056 loss_total_corr:-0.457 \n",
      "epoch: 28 total time: 248.0, epoch time: 8.0, loss: 0.516 loss_corr:-0.487 loss_mse: 8.071 loss_res_mse: 1.052 loss_total_corr:-0.457 \n",
      "epoch: 29 total time: 256.5, epoch time: 8.3, loss: 0.315 loss_corr:-0.481 loss_mse: 8.206 loss_res_mse: 1.064 loss_total_corr:-0.450 \n",
      "epoch: 30 total time: 264.2, epoch time: 7.6, loss: 0.091 loss_corr:-0.484 loss_mse: 8.184 loss_res_mse: 1.059 loss_total_corr:-0.453 \n",
      "epoch: 31 total time: 272.3, epoch time: 8.0, loss:-0.139 loss_corr:-0.493 loss_mse: 8.039 loss_res_mse: 1.042 loss_total_corr:-0.463 \n",
      "epoch: 32 total time: 280.1, epoch time: 7.7, loss:-0.297 loss_corr:-0.488 loss_mse: 8.062 loss_res_mse: 1.052 loss_total_corr:-0.458 \n",
      "epoch: 33 total time: 289.4, epoch time: 9.2, loss:-0.477 loss_corr:-0.498 loss_mse: 7.946 loss_res_mse: 1.036 loss_total_corr:-0.468 \n",
      "epoch: 34 total time: 297.6, epoch time: 8.1, loss:-0.576 loss_corr:-0.486 loss_mse: 8.114 loss_res_mse: 1.055 loss_total_corr:-0.457 \n",
      "epoch: 35 total time: 306.2, epoch time: 8.3, loss:-0.671 loss_corr:-0.480 loss_mse: 8.219 loss_res_mse: 1.067 loss_total_corr:-0.450 \n",
      "epoch: 36 total time: 313.9, epoch time: 7.6, loss:-0.783 loss_corr:-0.488 loss_mse: 8.149 loss_res_mse: 1.051 loss_total_corr:-0.458 \n",
      "epoch: 37 total time: 321.5, epoch time: 7.5, loss:-0.852 loss_corr:-0.487 loss_mse: 8.104 loss_res_mse: 1.054 loss_total_corr:-0.457 \n",
      "epoch: 38 total time: 329.7, epoch time: 8.2, loss:-0.911 loss_corr:-0.491 loss_mse: 8.041 loss_res_mse: 1.051 loss_total_corr:-0.461 \n",
      "epoch: 39 total time: 337.4, epoch time: 7.6, loss:-0.923 loss_corr:-0.481 loss_mse: 8.177 loss_res_mse: 1.059 loss_total_corr:-0.452 \n",
      "completed training\n",
      "model parameter summary:\n",
      "\ty_loc:\t\t\t1.2151e-01 +- 1.0156e+00. max=1.1209e+01 min=-4.2539e-01\n",
      "\ty_scale:\t\t\t2.7663e+00 +- 9.9743e-01. max=8.3332e+00 min=1.6935e+00\n",
      "\tinputs_decomposer_components:\t\t\t1.9875e-04 +- 2.5819e-02. max=1.4777e-01 min=-1.5526e-01\n",
      "\ttargets_decomposer_components:\t\t\t4.0042e-04 +- 2.5817e-02. max=3.3770e-01 min=-2.5994e-01\n",
      "\ttargets_global_median:\t\t\t-2.0457e-01 +- 4.3035e-01. max=5.7632e+00 min=-3.5212e-01\n",
      "\tgender_embedding:\t\t\t4.9887e-01 +- 2.8988e-01. max=9.9978e-01 min=8.5056e-05\n",
      "\tencoder.layers.0.fc.weight:\t\t\t-8.3995e-06 +- 1.2760e-02. max=2.3277e-02 min=-2.3370e-02\n",
      "\tencoder.layers.0.norm.weight:\t\t\t1.0000e+00 +- 3.9723e-04. max=1.0015e+00 min=9.9894e-01\n",
      "\tencoder.layers.0.norm.bias:\t\t\t1.9024e-07 +- 3.1998e-04. max=9.8234e-04 min=-9.4663e-04\n",
      "\tencoder.out_fc.weight:\t\t\t-5.2614e-06 +- 1.2757e-02. max=2.3229e-02 min=-2.3194e-02\n",
      "\tencoder.out_fc.bias:\t\t\t1.1962e-04 +- 1.2785e-02. max=2.2203e-02 min=-2.2473e-02\n",
      "\tdecoder.in_fc.weight:\t\t\t-9.0937e-06 +- 1.2764e-02. max=2.3237e-02 min=-2.3334e-02\n",
      "\tdecoder.in_fc.bias:\t\t\t5.8847e-05 +- 1.2854e-02. max=2.2409e-02 min=-2.2288e-02\n",
      "\tdecoder.layers.0.fc.weight:\t\t\t5.4459e-06 +- 1.2761e-02. max=2.3638e-02 min=-2.3271e-02\n",
      "\tdecoder.layers.0.norm.weight:\t\t\t9.9982e-01 +- 3.3515e-04. max=1.0011e+00 min=9.9895e-01\n",
      "\tdecoder.layers.0.norm.bias:\t\t\t2.5353e-07 +- 2.6076e-04. max=8.9523e-04 min=-8.4591e-04\n",
      "\tdecoder.layers.1.fc.weight:\t\t\t-1.0878e-06 +- 1.2754e-02. max=2.3335e-02 min=-2.3407e-02\n",
      "\tdecoder.layers.1.norm.weight:\t\t\t9.9975e-01 +- 3.3243e-04. max=1.0012e+00 min=9.9884e-01\n",
      "\tdecoder.layers.1.norm.bias:\t\t\t1.5793e-05 +- 3.0057e-04. max=1.1372e-03 min=-9.8654e-04\n",
      "\tdecoder.layers.2.fc.weight:\t\t\t6.7485e-06 +- 1.2752e-02. max=2.3348e-02 min=-2.3246e-02\n",
      "\tdecoder.layers.2.norm.weight:\t\t\t9.9965e-01 +- 3.2655e-04. max=1.0010e+00 min=9.9875e-01\n",
      "\tdecoder.layers.2.norm.bias:\t\t\t8.9356e-06 +- 3.2161e-04. max=1.0029e-03 min=-9.7125e-04\n",
      "\tdecoder.layers.3.fc.weight:\t\t\t1.3750e-05 +- 1.2753e-02. max=2.3199e-02 min=-2.3339e-02\n",
      "\tdecoder.layers.3.norm.weight:\t\t\t9.9952e-01 +- 3.0870e-04. max=1.0008e+00 min=9.9870e-01\n",
      "\tdecoder.layers.3.norm.bias:\t\t\t7.3516e-06 +- 3.2755e-04. max=1.0446e-03 min=-1.0011e-03\n",
      "\tdecoder.layers.4.fc.weight:\t\t\t-2.3450e-07 +- 1.2746e-02. max=2.3308e-02 min=-2.3312e-02\n",
      "\tdecoder.layers.4.norm.weight:\t\t\t9.9929e-01 +- 2.6654e-04. max=1.0005e+00 min=9.9845e-01\n",
      "\tdecoder.layers.4.norm.bias:\t\t\t-3.4088e-06 +- 3.5920e-04. max=1.1264e-03 min=-1.0241e-03\n",
      "\tencoder_in_fc.weight:\t\t\t1.3913e-05 +- 3.5581e-02. max=6.2960e-02 min=-6.2917e-02\n",
      "\tencoder_in_fc.bias:\t\t\t2.0047e-03 +- 3.5583e-02. max=6.2042e-02 min=-6.1302e-02\n",
      "\tdecoder_out_fcs.0.weight:\t\t\t-8.7556e-06 +- 1.2779e-02. max=2.3603e-02 min=-2.3592e-02\n",
      "\tdecoder_out_fcs.0.bias:\t\t\t4.0352e-04 +- 1.3367e-02. max=2.2010e-02 min=-2.2003e-02\n",
      "\tdecoder_out_fcs.1.weight:\t\t\t3.3775e-06 +- 1.2696e-02. max=2.3309e-02 min=-2.3377e-02\n",
      "\tdecoder_out_fcs.1.bias:\t\t\t-2.7295e-04 +- 1.3001e-02. max=2.1930e-02 min=-2.1731e-02\n",
      "\tdecoder_out_fcs.2.weight:\t\t\t2.6645e-06 +- 1.2726e-02. max=2.3209e-02 min=-2.3117e-02\n",
      "\tdecoder_out_fcs.2.bias:\t\t\t-6.2029e-04 +- 1.2969e-02. max=2.2871e-02 min=-2.1981e-02\n",
      "\tdecoder_out_fcs.3.weight:\t\t\t-9.5312e-07 +- 1.2672e-02. max=2.3068e-02 min=-2.3222e-02\n",
      "\tdecoder_out_fcs.3.bias:\t\t\t1.5284e-03 +- 1.3405e-02. max=2.1736e-02 min=-2.1966e-02\n",
      "\tdecoder_out_fcs.4.weight:\t\t\t-2.6713e-05 +- 1.2684e-02. max=2.3061e-02 min=-2.3029e-02\n",
      "\tdecoder_out_fcs.4.bias:\t\t\t1.3950e-04 +- 1.3269e-02. max=2.2071e-02 min=-2.1888e-02\n",
      "\tdecoder_out_fcs.5.weight:\t\t\t1.0999e-05 +- 1.2681e-02. max=2.3019e-02 min=-2.3111e-02\n",
      "\tdecoder_out_fcs.5.bias:\t\t\t-1.5948e-03 +- 1.3173e-02. max=2.2290e-02 min=-2.2141e-02\n",
      "\tdecoder_out_res_fcs.0.weight:\t\t\t5.9361e-06 +- 1.2756e-02. max=2.4017e-02 min=-2.4018e-02\n",
      "\tdecoder_out_res_fcs.0.bias:\t\t\t1.6642e-04 +- 1.2618e-02. max=2.2881e-02 min=-2.2517e-02\n",
      "\tdecoder_out_res_fcs.1.weight:\t\t\t-3.7721e-06 +- 1.2697e-02. max=2.3717e-02 min=-2.3945e-02\n",
      "\tdecoder_out_res_fcs.1.bias:\t\t\t-3.5172e-05 +- 1.3002e-02. max=2.2870e-02 min=-2.2795e-02\n",
      "\tdecoder_out_res_fcs.2.weight:\t\t\t1.2887e-05 +- 1.2684e-02. max=2.3762e-02 min=-2.3762e-02\n",
      "\tdecoder_out_res_fcs.2.bias:\t\t\t1.4341e-04 +- 1.2638e-02. max=2.3673e-02 min=-2.3084e-02\n",
      "\tdecoder_out_res_fcs.3.weight:\t\t\t-1.1159e-05 +- 1.2676e-02. max=2.3619e-02 min=-2.3742e-02\n",
      "\tdecoder_out_res_fcs.3.bias:\t\t\t-1.6130e-04 +- 1.2848e-02. max=2.3420e-02 min=-2.3162e-02\n",
      "\tdecoder_out_res_fcs.4.weight:\t\t\t-6.4095e-07 +- 1.2659e-02. max=2.3620e-02 min=-2.3648e-02\n",
      "\tdecoder_out_res_fcs.4.bias:\t\t\t8.4820e-04 +- 1.2731e-02. max=2.2876e-02 min=-2.2943e-02\n",
      "\tdecoder_out_res_fcs.5.weight:\t\t\t1.1689e-05 +- 1.2654e-02. max=2.3575e-02 min=-2.3519e-02\n",
      "\tdecoder_out_res_fcs.5.bias:\t\t\t2.7926e-04 +- 1.2629e-02. max=2.3141e-02 min=-2.2994e-02\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "Fold 1 bagging 0 mse_train:  1.17672 corrscore_train:  0.55430 mse_val:  1.51256 corrscore_val:  0.42653 \n",
      "Fold 1: score:{'mse_train': 1.1767232, 'corrscore_train': 0.5543028435678142, 'unknown_mse_train': 1.1767232, 'unknown_corrscore_train': 0.5543028435678142, 'mse_val': 1.5125625, 'corrscore_val': 0.4265302777856164, 'unknown_mse_val': 1.5125625, 'unknown_corrscore_val': 0.4265302777856164} elapsed time =  346.927\n",
      "train group: [0 1]\n",
      "val group: [2 3]\n",
      "skip pre_post_process fit\n",
      "Changing upper quantile to 0.999\n",
      "model input shape X:(120, 256) Y:(120, 128)\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "dataset size 120\n",
      "start to train\n",
      "epoch: 0 total time: 7.7, epoch time: 7.7, loss: 10.358 loss_corr:-0.383 loss_mse: 9.732 loss_res_mse: 1.369 loss_total_corr:-0.361 \n",
      "epoch: 1 total time: 15.7, epoch time: 7.8, loss: 10.587 loss_corr:-0.371 loss_mse: 9.911 loss_res_mse: 1.396 loss_total_corr:-0.348 \n",
      "epoch: 2 total time: 23.7, epoch time: 8.0, loss: 10.612 loss_corr:-0.373 loss_mse: 9.943 loss_res_mse: 1.391 loss_total_corr:-0.350 \n",
      "epoch: 3 total time: 31.6, epoch time: 7.8, loss: 10.529 loss_corr:-0.373 loss_mse: 9.869 loss_res_mse: 1.385 loss_total_corr:-0.352 \n",
      "epoch: 4 total time: 39.8, epoch time: 8.2, loss: 10.285 loss_corr:-0.386 loss_mse: 9.674 loss_res_mse: 1.360 loss_total_corr:-0.363 \n",
      "epoch: 5 total time: 48.6, epoch time: 8.7, loss: 10.081 loss_corr:-0.392 loss_mse: 9.492 loss_res_mse: 1.347 loss_total_corr:-0.367 \n",
      "epoch: 6 total time: 57.3, epoch time: 8.6, loss: 10.091 loss_corr:-0.396 loss_mse: 9.525 loss_res_mse: 1.334 loss_total_corr:-0.371 \n",
      "epoch: 7 total time: 65.3, epoch time: 7.9, loss: 10.131 loss_corr:-0.392 loss_mse: 9.553 loss_res_mse: 1.337 loss_total_corr:-0.368 \n",
      "epoch: 8 total time: 73.6, epoch time: 8.3, loss: 10.084 loss_corr:-0.396 loss_mse: 9.530 loss_res_mse: 1.322 loss_total_corr:-0.372 \n",
      "epoch: 9 total time: 81.5, epoch time: 7.8, loss: 9.812 loss_corr:-0.407 loss_mse: 9.310 loss_res_mse: 1.291 loss_total_corr:-0.382 \n",
      "epoch: 10 total time: 89.5, epoch time: 7.9, loss: 9.843 loss_corr:-0.404 loss_mse: 9.336 loss_res_mse: 1.289 loss_total_corr:-0.378 \n",
      "epoch: 11 total time: 97.5, epoch time: 8.0, loss: 8.986 loss_corr:-0.412 loss_mse: 9.202 loss_res_mse: 1.267 loss_total_corr:-0.385 \n",
      "epoch: 12 total time: 105.6, epoch time: 8.0, loss: 8.214 loss_corr:-0.420 loss_mse: 9.118 loss_res_mse: 1.244 loss_total_corr:-0.392 \n",
      "epoch: 13 total time: 114.0, epoch time: 8.3, loss: 7.526 loss_corr:-0.422 loss_mse: 9.069 loss_res_mse: 1.229 loss_total_corr:-0.393 \n",
      "epoch: 14 total time: 122.5, epoch time: 8.4, loss: 6.731 loss_corr:-0.436 loss_mse: 8.884 loss_res_mse: 1.197 loss_total_corr:-0.405 \n",
      "epoch: 15 total time: 130.9, epoch time: 8.3, loss: 6.190 loss_corr:-0.431 loss_mse: 8.911 loss_res_mse: 1.199 loss_total_corr:-0.400 \n",
      "epoch: 16 total time: 138.9, epoch time: 7.9, loss: 5.628 loss_corr:-0.432 loss_mse: 8.910 loss_res_mse: 1.185 loss_total_corr:-0.401 \n",
      "epoch: 17 total time: 147.0, epoch time: 8.0, loss: 4.869 loss_corr:-0.451 loss_mse: 8.619 loss_res_mse: 1.143 loss_total_corr:-0.418 \n",
      "epoch: 18 total time: 155.3, epoch time: 8.2, loss: 4.461 loss_corr:-0.450 loss_mse: 8.763 loss_res_mse: 1.144 loss_total_corr:-0.417 \n",
      "epoch: 19 total time: 164.8, epoch time: 9.4, loss: 3.751 loss_corr:-0.467 loss_mse: 8.392 loss_res_mse: 1.103 loss_total_corr:-0.434 \n",
      "epoch: 20 total time: 172.7, epoch time: 7.7, loss: 3.386 loss_corr:-0.460 loss_mse: 8.507 loss_res_mse: 1.110 loss_total_corr:-0.429 \n",
      "epoch: 21 total time: 180.9, epoch time: 8.1, loss: 3.002 loss_corr:-0.457 loss_mse: 8.567 loss_res_mse: 1.114 loss_total_corr:-0.424 \n",
      "epoch: 22 total time: 188.7, epoch time: 7.8, loss: 2.568 loss_corr:-0.463 loss_mse: 8.507 loss_res_mse: 1.104 loss_total_corr:-0.430 \n",
      "epoch: 23 total time: 196.3, epoch time: 7.4, loss: 2.172 loss_corr:-0.466 loss_mse: 8.477 loss_res_mse: 1.092 loss_total_corr:-0.434 \n",
      "epoch: 24 total time: 203.9, epoch time: 7.6, loss: 1.810 loss_corr:-0.467 loss_mse: 8.448 loss_res_mse: 1.087 loss_total_corr:-0.435 \n",
      "epoch: 25 total time: 211.8, epoch time: 7.8, loss: 1.430 loss_corr:-0.472 loss_mse: 8.290 loss_res_mse: 1.081 loss_total_corr:-0.440 \n",
      "epoch: 26 total time: 219.6, epoch time: 7.7, loss: 1.107 loss_corr:-0.478 loss_mse: 8.255 loss_res_mse: 1.068 loss_total_corr:-0.446 \n",
      "epoch: 27 total time: 227.5, epoch time: 7.9, loss: 0.811 loss_corr:-0.482 loss_mse: 8.222 loss_res_mse: 1.061 loss_total_corr:-0.450 \n",
      "epoch: 28 total time: 235.4, epoch time: 7.8, loss: 0.500 loss_corr:-0.492 loss_mse: 8.036 loss_res_mse: 1.044 loss_total_corr:-0.461 \n",
      "epoch: 29 total time: 243.3, epoch time: 7.8, loss: 0.319 loss_corr:-0.480 loss_mse: 8.224 loss_res_mse: 1.064 loss_total_corr:-0.449 \n",
      "epoch: 30 total time: 251.2, epoch time: 7.8, loss: 0.115 loss_corr:-0.476 loss_mse: 8.263 loss_res_mse: 1.070 loss_total_corr:-0.446 \n",
      "epoch: 31 total time: 259.5, epoch time: 8.2, loss:-0.105 loss_corr:-0.484 loss_mse: 8.206 loss_res_mse: 1.055 loss_total_corr:-0.455 \n",
      "epoch: 32 total time: 267.5, epoch time: 8.0, loss:-0.282 loss_corr:-0.484 loss_mse: 8.165 loss_res_mse: 1.056 loss_total_corr:-0.454 \n",
      "epoch: 33 total time: 275.5, epoch time: 7.8, loss:-0.427 loss_corr:-0.482 loss_mse: 8.267 loss_res_mse: 1.060 loss_total_corr:-0.453 \n",
      "epoch: 34 total time: 284.6, epoch time: 9.0, loss:-0.557 loss_corr:-0.480 loss_mse: 8.242 loss_res_mse: 1.062 loss_total_corr:-0.450 \n",
      "epoch: 35 total time: 293.1, epoch time: 8.3, loss:-0.655 loss_corr:-0.474 loss_mse: 8.330 loss_res_mse: 1.076 loss_total_corr:-0.443 \n",
      "epoch: 36 total time: 301.2, epoch time: 8.0, loss:-0.770 loss_corr:-0.482 loss_mse: 8.197 loss_res_mse: 1.058 loss_total_corr:-0.453 \n",
      "epoch: 37 total time: 309.1, epoch time: 7.8, loss:-0.844 loss_corr:-0.482 loss_mse: 8.151 loss_res_mse: 1.056 loss_total_corr:-0.454 \n",
      "epoch: 38 total time: 316.9, epoch time: 7.8, loss:-0.891 loss_corr:-0.482 loss_mse: 8.286 loss_res_mse: 1.060 loss_total_corr:-0.451 \n",
      "epoch: 39 total time: 325.1, epoch time: 8.1, loss:-0.929 loss_corr:-0.485 loss_mse: 8.163 loss_res_mse: 1.054 loss_total_corr:-0.454 \n",
      "completed training\n",
      "model parameter summary:\n",
      "\ty_loc:\t\t\t1.0158e-01 +- 1.0216e+00. max=1.1428e+01 min=-6.2819e-01\n",
      "\ty_scale:\t\t\t2.7818e+00 +- 9.5463e-01. max=7.6061e+00 min=1.6187e+00\n",
      "\tinputs_decomposer_components:\t\t\t1.9875e-04 +- 2.5819e-02. max=1.4777e-01 min=-1.5526e-01\n",
      "\ttargets_decomposer_components:\t\t\t4.0042e-04 +- 2.5817e-02. max=3.3770e-01 min=-2.5994e-01\n",
      "\ttargets_global_median:\t\t\t-2.0457e-01 +- 4.3035e-01. max=5.7632e+00 min=-3.5212e-01\n",
      "\tgender_embedding:\t\t\t4.9539e-01 +- 2.8675e-01. max=9.9958e-01 min=5.2124e-04\n",
      "\tencoder.layers.0.fc.weight:\t\t\t-1.5942e-06 +- 1.2761e-02. max=2.3306e-02 min=-2.3341e-02\n",
      "\tencoder.layers.0.norm.weight:\t\t\t1.0000e+00 +- 4.1486e-04. max=1.0013e+00 min=9.9883e-01\n",
      "\tencoder.layers.0.norm.bias:\t\t\t-1.7654e-06 +- 3.2133e-04. max=1.1112e-03 min=-1.0349e-03\n",
      "\tencoder.out_fc.weight:\t\t\t-4.4273e-06 +- 1.2766e-02. max=2.3324e-02 min=-2.3173e-02\n",
      "\tencoder.out_fc.bias:\t\t\t-3.2019e-04 +- 1.2728e-02. max=2.2323e-02 min=-2.2145e-02\n",
      "\tdecoder.in_fc.weight:\t\t\t-1.3607e-05 +- 1.2759e-02. max=2.3289e-02 min=-2.3252e-02\n",
      "\tdecoder.in_fc.bias:\t\t\t3.0720e-04 +- 1.2822e-02. max=2.2437e-02 min=-2.2351e-02\n",
      "\tdecoder.layers.0.fc.weight:\t\t\t-5.0055e-06 +- 1.2754e-02. max=2.3337e-02 min=-2.3177e-02\n",
      "\tdecoder.layers.0.norm.weight:\t\t\t9.9980e-01 +- 3.3499e-04. max=1.0011e+00 min=9.9891e-01\n",
      "\tdecoder.layers.0.norm.bias:\t\t\t-3.5908e-08 +- 2.6132e-04. max=1.0324e-03 min=-8.9741e-04\n",
      "\tdecoder.layers.1.fc.weight:\t\t\t3.2035e-06 +- 1.2756e-02. max=2.3384e-02 min=-2.3210e-02\n",
      "\tdecoder.layers.1.norm.weight:\t\t\t9.9973e-01 +- 3.3499e-04. max=1.0009e+00 min=9.9876e-01\n",
      "\tdecoder.layers.1.norm.bias:\t\t\t9.8808e-06 +- 2.9037e-04. max=8.8644e-04 min=-9.5211e-04\n",
      "\tdecoder.layers.2.fc.weight:\t\t\t-7.9736e-07 +- 1.2749e-02. max=2.3259e-02 min=-2.3124e-02\n",
      "\tdecoder.layers.2.norm.weight:\t\t\t9.9964e-01 +- 3.2323e-04. max=1.0008e+00 min=9.9871e-01\n",
      "\tdecoder.layers.2.norm.bias:\t\t\t-3.0360e-06 +- 3.0121e-04. max=1.0011e-03 min=-9.4831e-04\n",
      "\tdecoder.layers.3.fc.weight:\t\t\t-1.5375e-06 +- 1.2754e-02. max=2.3282e-02 min=-2.3196e-02\n",
      "\tdecoder.layers.3.norm.weight:\t\t\t9.9952e-01 +- 3.0944e-04. max=1.0010e+00 min=9.9863e-01\n",
      "\tdecoder.layers.3.norm.bias:\t\t\t1.2324e-06 +- 3.0954e-04. max=8.9962e-04 min=-9.2202e-04\n",
      "\tdecoder.layers.4.fc.weight:\t\t\t3.3678e-07 +- 1.2742e-02. max=2.3229e-02 min=-2.3157e-02\n",
      "\tdecoder.layers.4.norm.weight:\t\t\t9.9927e-01 +- 2.6183e-04. max=1.0003e+00 min=9.9846e-01\n",
      "\tdecoder.layers.4.norm.bias:\t\t\t1.1489e-05 +- 3.3654e-04. max=9.7994e-04 min=-9.6302e-04\n",
      "\tencoder_in_fc.weight:\t\t\t1.0916e-04 +- 3.5622e-02. max=6.2872e-02 min=-6.2896e-02\n",
      "\tencoder_in_fc.bias:\t\t\t4.1800e-04 +- 3.4892e-02. max=6.1340e-02 min=-6.1788e-02\n",
      "\tdecoder_out_fcs.0.weight:\t\t\t3.0560e-06 +- 1.2738e-02. max=2.3540e-02 min=-2.3649e-02\n",
      "\tdecoder_out_fcs.0.bias:\t\t\t-4.1246e-04 +- 1.2270e-02. max=2.1809e-02 min=-2.0871e-02\n",
      "\tdecoder_out_fcs.1.weight:\t\t\t7.2670e-06 +- 1.2697e-02. max=2.3289e-02 min=-2.3290e-02\n",
      "\tdecoder_out_fcs.1.bias:\t\t\t4.1193e-04 +- 1.2419e-02. max=2.1836e-02 min=-2.1868e-02\n",
      "\tdecoder_out_fcs.2.weight:\t\t\t-3.6762e-05 +- 1.2713e-02. max=2.3200e-02 min=-2.3231e-02\n",
      "\tdecoder_out_fcs.2.bias:\t\t\t-1.1443e-03 +- 1.3053e-02. max=2.1737e-02 min=-2.2135e-02\n",
      "\tdecoder_out_fcs.3.weight:\t\t\t-4.6027e-05 +- 1.2688e-02. max=2.3311e-02 min=-2.3097e-02\n",
      "\tdecoder_out_fcs.3.bias:\t\t\t-1.2516e-03 +- 1.2581e-02. max=2.1721e-02 min=-2.1939e-02\n",
      "\tdecoder_out_fcs.4.weight:\t\t\t4.1480e-05 +- 1.2690e-02. max=2.3251e-02 min=-2.2991e-02\n",
      "\tdecoder_out_fcs.4.bias:\t\t\t2.0809e-04 +- 1.3269e-02. max=2.2391e-02 min=-2.2079e-02\n",
      "\tdecoder_out_fcs.5.weight:\t\t\t1.5947e-05 +- 1.2672e-02. max=2.2910e-02 min=-2.3100e-02\n",
      "\tdecoder_out_fcs.5.bias:\t\t\t8.4023e-05 +- 1.3311e-02. max=2.2237e-02 min=-2.1930e-02\n",
      "\tdecoder_out_res_fcs.0.weight:\t\t\t-8.2726e-06 +- 1.2751e-02. max=2.3940e-02 min=-2.3989e-02\n",
      "\tdecoder_out_res_fcs.0.bias:\t\t\t6.2893e-04 +- 1.2609e-02. max=2.3038e-02 min=-2.2999e-02\n",
      "\tdecoder_out_res_fcs.1.weight:\t\t\t-3.8642e-06 +- 1.2699e-02. max=2.3806e-02 min=-2.3956e-02\n",
      "\tdecoder_out_res_fcs.1.bias:\t\t\t-1.4069e-05 +- 1.2597e-02. max=2.2532e-02 min=-2.2708e-02\n",
      "\tdecoder_out_res_fcs.2.weight:\t\t\t3.6838e-06 +- 1.2687e-02. max=2.3852e-02 min=-2.3820e-02\n",
      "\tdecoder_out_res_fcs.2.bias:\t\t\t5.6856e-04 +- 1.2598e-02. max=2.3002e-02 min=-2.3461e-02\n",
      "\tdecoder_out_res_fcs.3.weight:\t\t\t-1.9654e-06 +- 1.2670e-02. max=2.3834e-02 min=-2.3946e-02\n",
      "\tdecoder_out_res_fcs.3.bias:\t\t\t2.2538e-04 +- 1.2606e-02. max=2.2800e-02 min=-2.2482e-02\n",
      "\tdecoder_out_res_fcs.4.weight:\t\t\t6.2752e-06 +- 1.2666e-02. max=2.3732e-02 min=-2.3593e-02\n",
      "\tdecoder_out_res_fcs.4.bias:\t\t\t3.8753e-04 +- 1.2582e-02. max=2.3496e-02 min=-2.2922e-02\n",
      "\tdecoder_out_res_fcs.5.weight:\t\t\t1.0203e-05 +- 1.2658e-02. max=2.3731e-02 min=-2.3642e-02\n",
      "\tdecoder_out_res_fcs.5.bias:\t\t\t6.5795e-04 +- 1.2739e-02. max=2.3219e-02 min=-2.3274e-02\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "Fold 2 bagging 0 mse_train:  1.20597 corrscore_train:  0.54882 mse_val:  1.44761 corrscore_val:  0.44307 \n",
      "Fold 2: score:{'mse_train': 1.2059735, 'corrscore_train': 0.5488194068419695, 'unknown_mse_train': 1.2059735, 'unknown_corrscore_train': 0.5488194068419695, 'mse_val': 1.4476105, 'corrscore_val': 0.44307306746948993, 'unknown_mse_val': 1.4476105, 'unknown_corrscore_val': 0.44307306746948993} elapsed time =  333.511\n",
      "Average: mse_train                  1.194722\n",
      "corrscore_train            0.554446\n",
      "mse_val                    1.457226\n",
      "corrscore_val              0.435854\n",
      "unknown_mse_train          1.194722\n",
      "unknown_corrscore_train    0.554446\n",
      "unknown_mse_val            1.457226\n",
      "unknown_corrscore_val      0.435854\n",
      "dtype: float64\n",
      "train model to predict with test data\n",
      "skip pre_post_process fit\n",
      "Changing upper quantile to 0.999\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "dataset size 171\n",
      "start to train\n",
      "epoch: 0 total time: 8.7, epoch time: 8.6, loss: 10.635 loss_corr:-0.367 loss_mse: 9.943 loss_res_mse: 1.404 loss_total_corr:-0.345 \n",
      "epoch: 1 total time: 17.3, epoch time: 8.6, loss: 10.376 loss_corr:-0.382 loss_mse: 9.746 loss_res_mse: 1.372 loss_total_corr:-0.359 \n",
      "epoch: 2 total time: 25.6, epoch time: 8.1, loss: 10.412 loss_corr:-0.380 loss_mse: 9.777 loss_res_mse: 1.372 loss_total_corr:-0.357 \n",
      "epoch: 3 total time: 33.7, epoch time: 8.1, loss: 10.301 loss_corr:-0.383 loss_mse: 9.678 loss_res_mse: 1.366 loss_total_corr:-0.359 \n",
      "epoch: 4 total time: 41.5, epoch time: 7.7, loss: 10.086 loss_corr:-0.395 loss_mse: 9.516 loss_res_mse: 1.336 loss_total_corr:-0.370 \n",
      "epoch: 5 total time: 49.7, epoch time: 8.1, loss: 10.086 loss_corr:-0.396 loss_mse: 9.529 loss_res_mse: 1.326 loss_total_corr:-0.372 \n",
      "epoch: 6 total time: 57.5, epoch time: 7.8, loss: 10.217 loss_corr:-0.388 loss_mse: 9.633 loss_res_mse: 1.334 loss_total_corr:-0.363 \n",
      "epoch: 7 total time: 65.5, epoch time: 7.8, loss: 9.845 loss_corr:-0.408 loss_mse: 9.349 loss_res_mse: 1.284 loss_total_corr:-0.381 \n",
      "epoch: 8 total time: 73.2, epoch time: 7.7, loss: 9.789 loss_corr:-0.407 loss_mse: 9.310 loss_res_mse: 1.267 loss_total_corr:-0.380 \n",
      "epoch: 9 total time: 81.1, epoch time: 7.8, loss: 9.604 loss_corr:-0.419 loss_mse: 9.179 loss_res_mse: 1.231 loss_total_corr:-0.388 \n",
      "epoch: 10 total time: 89.0, epoch time: 7.8, loss: 9.300 loss_corr:-0.430 loss_mse: 8.940 loss_res_mse: 1.188 loss_total_corr:-0.398 \n",
      "epoch: 11 total time: 96.8, epoch time: 7.7, loss: 8.516 loss_corr:-0.437 loss_mse: 8.853 loss_res_mse: 1.160 loss_total_corr:-0.403 \n",
      "epoch: 12 total time: 104.6, epoch time: 7.7, loss: 7.847 loss_corr:-0.440 loss_mse: 8.838 loss_res_mse: 1.137 loss_total_corr:-0.403 \n",
      "epoch: 13 total time: 114.2, epoch time: 9.6, loss: 6.985 loss_corr:-0.457 loss_mse: 8.604 loss_res_mse: 1.099 loss_total_corr:-0.418 \n",
      "epoch: 14 total time: 122.3, epoch time: 7.9, loss: 6.530 loss_corr:-0.443 loss_mse: 8.718 loss_res_mse: 1.106 loss_total_corr:-0.406 \n",
      "epoch: 15 total time: 130.5, epoch time: 8.2, loss: 5.546 loss_corr:-0.476 loss_mse: 8.247 loss_res_mse: 1.052 loss_total_corr:-0.435 \n",
      "epoch: 16 total time: 139.1, epoch time: 8.4, loss: 4.998 loss_corr:-0.481 loss_mse: 8.213 loss_res_mse: 1.039 loss_total_corr:-0.442 \n",
      "epoch: 17 total time: 147.4, epoch time: 8.2, loss: 4.611 loss_corr:-0.472 loss_mse: 8.349 loss_res_mse: 1.040 loss_total_corr:-0.435 \n",
      "epoch: 18 total time: 155.6, epoch time: 8.1, loss: 4.086 loss_corr:-0.478 loss_mse: 8.278 loss_res_mse: 1.027 loss_total_corr:-0.440 \n",
      "epoch: 19 total time: 163.7, epoch time: 8.0, loss: 3.479 loss_corr:-0.491 loss_mse: 8.028 loss_res_mse: 1.002 loss_total_corr:-0.454 \n",
      "epoch: 20 total time: 171.8, epoch time: 8.1, loss: 3.049 loss_corr:-0.492 loss_mse: 8.004 loss_res_mse: 0.994 loss_total_corr:-0.458 \n",
      "epoch: 21 total time: 180.1, epoch time: 8.2, loss: 2.697 loss_corr:-0.486 loss_mse: 8.058 loss_res_mse: 1.004 loss_total_corr:-0.453 \n",
      "epoch: 22 total time: 188.3, epoch time: 8.1, loss: 2.261 loss_corr:-0.497 loss_mse: 7.964 loss_res_mse: 0.983 loss_total_corr:-0.463 \n",
      "epoch: 23 total time: 196.5, epoch time: 8.2, loss: 1.979 loss_corr:-0.488 loss_mse: 8.106 loss_res_mse: 1.000 loss_total_corr:-0.458 \n",
      "epoch: 24 total time: 205.1, epoch time: 8.5, loss: 1.542 loss_corr:-0.500 loss_mse: 7.850 loss_res_mse: 0.977 loss_total_corr:-0.468 \n",
      "epoch: 25 total time: 213.5, epoch time: 8.3, loss: 1.277 loss_corr:-0.496 loss_mse: 7.956 loss_res_mse: 0.989 loss_total_corr:-0.464 \n",
      "epoch: 26 total time: 221.5, epoch time: 7.9, loss: 0.973 loss_corr:-0.499 loss_mse: 7.937 loss_res_mse: 0.984 loss_total_corr:-0.471 \n",
      "epoch: 27 total time: 230.7, epoch time: 9.2, loss: 0.665 loss_corr:-0.506 loss_mse: 7.819 loss_res_mse: 0.972 loss_total_corr:-0.479 \n",
      "epoch: 28 total time: 238.9, epoch time: 8.1, loss: 0.369 loss_corr:-0.516 loss_mse: 7.624 loss_res_mse: 0.959 loss_total_corr:-0.488 \n",
      "epoch: 29 total time: 246.8, epoch time: 7.8, loss: 0.225 loss_corr:-0.500 loss_mse: 7.913 loss_res_mse: 0.989 loss_total_corr:-0.472 \n",
      "epoch: 30 total time: 255.1, epoch time: 8.2, loss:-0.026 loss_corr:-0.511 loss_mse: 7.748 loss_res_mse: 0.969 loss_total_corr:-0.483 \n",
      "epoch: 31 total time: 263.2, epoch time: 8.0, loss:-0.193 loss_corr:-0.508 loss_mse: 7.853 loss_res_mse: 0.975 loss_total_corr:-0.480 \n",
      "epoch: 32 total time: 271.1, epoch time: 7.8, loss:-0.330 loss_corr:-0.498 loss_mse: 7.981 loss_res_mse: 0.994 loss_total_corr:-0.470 \n",
      "epoch: 33 total time: 278.9, epoch time: 7.7, loss:-0.514 loss_corr:-0.509 loss_mse: 7.809 loss_res_mse: 0.971 loss_total_corr:-0.483 \n",
      "epoch: 34 total time: 286.7, epoch time: 7.8, loss:-0.645 loss_corr:-0.511 loss_mse: 7.771 loss_res_mse: 0.973 loss_total_corr:-0.484 \n",
      "epoch: 35 total time: 294.5, epoch time: 7.7, loss:-0.748 loss_corr:-0.508 loss_mse: 7.744 loss_res_mse: 0.979 loss_total_corr:-0.482 \n",
      "epoch: 36 total time: 302.2, epoch time: 7.7, loss:-0.857 loss_corr:-0.518 loss_mse: 7.660 loss_res_mse: 0.958 loss_total_corr:-0.493 \n",
      "epoch: 37 total time: 310.2, epoch time: 7.9, loss:-0.920 loss_corr:-0.516 loss_mse: 7.656 loss_res_mse: 0.962 loss_total_corr:-0.490 \n",
      "epoch: 38 total time: 318.0, epoch time: 7.7, loss:-0.964 loss_corr:-0.513 loss_mse: 7.667 loss_res_mse: 0.969 loss_total_corr:-0.489 \n",
      "epoch: 39 total time: 325.9, epoch time: 7.9, loss:-0.965 loss_corr:-0.500 loss_mse: 7.906 loss_res_mse: 0.984 loss_total_corr:-0.476 \n",
      "completed training\n",
      "model parameter summary:\n",
      "\ty_loc:\t\t\t1.0281e-01 +- 1.0057e+00. max=1.1345e+01 min=-4.0265e-01\n",
      "\ty_scale:\t\t\t2.7879e+00 +- 9.4462e-01. max=7.7365e+00 min=1.6817e+00\n",
      "\tinputs_decomposer_components:\t\t\t1.9875e-04 +- 2.5819e-02. max=1.4777e-01 min=-1.5526e-01\n",
      "\ttargets_decomposer_components:\t\t\t4.0042e-04 +- 2.5817e-02. max=3.3770e-01 min=-2.5994e-01\n",
      "\ttargets_global_median:\t\t\t-2.0457e-01 +- 4.3035e-01. max=5.7632e+00 min=-3.5212e-01\n",
      "\tgender_embedding:\t\t\t4.8792e-01 +- 2.8688e-01. max=9.9965e-01 min=8.8215e-06\n",
      "\tencoder.layers.0.fc.weight:\t\t\t-5.1264e-06 +- 1.2770e-02. max=2.3944e-02 min=-2.4120e-02\n",
      "\tencoder.layers.0.norm.weight:\t\t\t1.0001e+00 +- 6.2520e-04. max=1.0025e+00 min=9.9841e-01\n",
      "\tencoder.layers.0.norm.bias:\t\t\t1.6330e-05 +- 4.9892e-04. max=1.4683e-03 min=-1.4144e-03\n",
      "\tencoder.out_fc.weight:\t\t\t-1.1685e-06 +- 1.2761e-02. max=2.3793e-02 min=-2.3699e-02\n",
      "\tencoder.out_fc.bias:\t\t\t-5.2106e-04 +- 1.2843e-02. max=2.2310e-02 min=-2.2436e-02\n",
      "\tdecoder.in_fc.weight:\t\t\t-6.8330e-06 +- 1.2765e-02. max=2.3962e-02 min=-2.3953e-02\n",
      "\tdecoder.in_fc.bias:\t\t\t5.7504e-04 +- 1.2595e-02. max=2.2260e-02 min=-2.2594e-02\n",
      "\tdecoder.layers.0.fc.weight:\t\t\t-5.7452e-07 +- 1.2756e-02. max=2.4210e-02 min=-2.3814e-02\n",
      "\tdecoder.layers.0.norm.weight:\t\t\t9.9968e-01 +- 4.3086e-04. max=1.0013e+00 min=9.9803e-01\n",
      "\tdecoder.layers.0.norm.bias:\t\t\t-3.5060e-06 +- 3.0897e-04. max=1.1610e-03 min=-1.1207e-03\n",
      "\tdecoder.layers.1.fc.weight:\t\t\t2.9050e-06 +- 1.2756e-02. max=2.4053e-02 min=-2.3950e-02\n",
      "\tdecoder.layers.1.norm.weight:\t\t\t9.9954e-01 +- 4.2445e-04. max=1.0010e+00 min=9.9829e-01\n",
      "\tdecoder.layers.1.norm.bias:\t\t\t-7.2228e-07 +- 3.6659e-04. max=1.1623e-03 min=-1.2120e-03\n",
      "\tdecoder.layers.2.fc.weight:\t\t\t1.1323e-06 +- 1.2750e-02. max=2.3974e-02 min=-2.3643e-02\n",
      "\tdecoder.layers.2.norm.weight:\t\t\t9.9938e-01 +- 4.4338e-04. max=1.0008e+00 min=9.9790e-01\n",
      "\tdecoder.layers.2.norm.bias:\t\t\t-5.4257e-06 +- 3.8462e-04. max=1.2617e-03 min=-1.2920e-03\n",
      "\tdecoder.layers.3.fc.weight:\t\t\t-4.8650e-06 +- 1.2744e-02. max=2.3802e-02 min=-2.3660e-02\n",
      "\tdecoder.layers.3.norm.weight:\t\t\t9.9915e-01 +- 4.1730e-04. max=1.0010e+00 min=9.9783e-01\n",
      "\tdecoder.layers.3.norm.bias:\t\t\t9.9363e-08 +- 3.9014e-04. max=1.4644e-03 min=-1.1783e-03\n",
      "\tdecoder.layers.4.fc.weight:\t\t\t3.2709e-06 +- 1.2735e-02. max=2.3514e-02 min=-2.3792e-02\n",
      "\tdecoder.layers.4.norm.weight:\t\t\t9.9873e-01 +- 4.2334e-04. max=1.0000e+00 min=9.9668e-01\n",
      "\tdecoder.layers.4.norm.bias:\t\t\t1.7329e-05 +- 4.3372e-04. max=1.5649e-03 min=-1.6953e-03\n",
      "\tencoder_in_fc.weight:\t\t\t4.1915e-05 +- 3.5625e-02. max=6.3723e-02 min=-6.3736e-02\n",
      "\tencoder_in_fc.bias:\t\t\t-4.5631e-04 +- 3.5325e-02. max=6.2557e-02 min=-6.2536e-02\n",
      "\tdecoder_out_fcs.0.weight:\t\t\t1.6208e-05 +- 1.2779e-02. max=2.5198e-02 min=-2.4839e-02\n",
      "\tdecoder_out_fcs.0.bias:\t\t\t1.1008e-03 +- 1.3110e-02. max=2.1820e-02 min=-2.2071e-02\n",
      "\tdecoder_out_fcs.1.weight:\t\t\t-4.6628e-05 +- 1.2681e-02. max=2.3926e-02 min=-2.4068e-02\n",
      "\tdecoder_out_fcs.1.bias:\t\t\t7.5822e-04 +- 1.2206e-02. max=2.1331e-02 min=-2.0840e-02\n",
      "\tdecoder_out_fcs.2.weight:\t\t\t4.4420e-07 +- 1.2655e-02. max=2.3841e-02 min=-2.3742e-02\n",
      "\tdecoder_out_fcs.2.bias:\t\t\t-2.7596e-04 +- 1.1890e-02. max=2.0916e-02 min=-2.1732e-02\n",
      "\tdecoder_out_fcs.3.weight:\t\t\t-2.2892e-06 +- 1.2635e-02. max=2.3689e-02 min=-2.3558e-02\n",
      "\tdecoder_out_fcs.3.bias:\t\t\t-7.9468e-04 +- 1.3515e-02. max=2.2579e-02 min=-2.3038e-02\n",
      "\tdecoder_out_fcs.4.weight:\t\t\t-1.5996e-05 +- 1.2617e-02. max=2.3400e-02 min=-2.3573e-02\n",
      "\tdecoder_out_fcs.4.bias:\t\t\t-9.9085e-04 +- 1.3348e-02. max=2.1152e-02 min=-2.1656e-02\n",
      "\tdecoder_out_fcs.5.weight:\t\t\t1.4206e-06 +- 1.2599e-02. max=2.3485e-02 min=-2.3840e-02\n",
      "\tdecoder_out_fcs.5.bias:\t\t\t-4.9381e-04 +- 1.2095e-02. max=2.0786e-02 min=-2.1948e-02\n",
      "\tdecoder_out_res_fcs.0.weight:\t\t\t7.1622e-06 +- 1.2738e-02. max=2.6179e-02 min=-2.6122e-02\n",
      "\tdecoder_out_res_fcs.0.bias:\t\t\t-1.5655e-04 +- 1.2672e-02. max=2.3281e-02 min=-2.3465e-02\n",
      "\tdecoder_out_res_fcs.1.weight:\t\t\t8.9901e-07 +- 1.2650e-02. max=2.5294e-02 min=-2.5071e-02\n",
      "\tdecoder_out_res_fcs.1.bias:\t\t\t-1.2291e-04 +- 1.2869e-02. max=2.2886e-02 min=-2.2754e-02\n",
      "\tdecoder_out_res_fcs.2.weight:\t\t\t-1.0868e-05 +- 1.2624e-02. max=2.5096e-02 min=-2.5251e-02\n",
      "\tdecoder_out_res_fcs.2.bias:\t\t\t5.6024e-04 +- 1.2811e-02. max=2.2698e-02 min=-2.3426e-02\n",
      "\tdecoder_out_res_fcs.3.weight:\t\t\t1.0983e-05 +- 1.2606e-02. max=2.5100e-02 min=-2.5186e-02\n",
      "\tdecoder_out_res_fcs.3.bias:\t\t\t-2.5023e-04 +- 1.2713e-02. max=2.3201e-02 min=-2.2820e-02\n",
      "\tdecoder_out_res_fcs.4.weight:\t\t\t6.2025e-06 +- 1.2591e-02. max=2.4870e-02 min=-2.5627e-02\n",
      "\tdecoder_out_res_fcs.4.bias:\t\t\t3.0902e-04 +- 1.2766e-02. max=2.3671e-02 min=-2.3872e-02\n",
      "\tdecoder_out_res_fcs.5.weight:\t\t\t-4.2286e-06 +- 1.2572e-02. max=2.5243e-02 min=-2.5511e-02\n",
      "\tdecoder_out_res_fcs.5.bias:\t\t\t2.1043e-04 +- 1.2667e-02. max=2.4038e-02 min=-2.3507e-02\n",
      "elapsed time =  333.697\n",
      "pridict with test data\n",
      "There are columns with NaNs: Index(['cell_ratio_unknown'], dtype='object')\n",
      "Replacing NaNs with zeros\n",
      "elapsed time =  1.030\n",
      "dump preprocess and model\n",
      "save results\n",
      "completed !\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "export DATA_DIR=/Users/vladimir.shitov/Documents/programming/OpenProblems2022Analysis/data/\n",
    "\n",
    "cd rank1/open-problems-multimodal/\n",
    "python3 script/make_compressed_dataset.py --data_dir ${DATA_DIR}\n",
    "python3 script/make_additional_files.py --data_dir ${DATA_DIR}\n",
    "python3 script/make_compressed_dataset.py --data_dir ${DATA_DIR}\n",
    "python3 script/train_model.py --data_dir ${DATA_DIR} --task_type multi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are saved as pickled numpy array. Let's read them and calculate a correlation score to ground truth. We can import a function to compute the metric directly from competitor's code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"rank1/open-problems-multimodal\")  # Make it possible to import from competitor's code\n",
    "\n",
    "from ss_opm.metric.correlation_score import correlation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"rank1/open-problems-multimodal/result/multimodal_pred.pickle\", \"rb\") as f:\n",
    "    y_pred = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 1500)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48803106, -0.65492237, -0.6615395 , ...,  0.50882393,\n",
       "        -0.6830433 , -0.69751734],\n",
       "       [ 0.0964658 , -0.6530562 , -0.5683277 , ...,  0.989331  ,\n",
       "        -0.04067516, -0.47889504],\n",
       "       [ 0.6118262 , -0.7402453 , -0.42986473, ..., -0.02475481,\n",
       "         0.09570294, -0.4786224 ],\n",
       "       ...,\n",
       "       [ 0.32633352, -0.5289058 , -0.60409075, ...,  1.2354933 ,\n",
       "        -0.42940715, -0.5399292 ],\n",
       "       [ 0.54016536, -0.5665478 , -0.583822  , ...,  1.350588  ,\n",
       "        -0.02383605, -0.25707066],\n",
       "       [-0.1975743 , -0.556948  , -0.6063245 , ...,  0.92392415,\n",
       "        -0.6779063 , -0.6611087 ]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3650121607214872"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = adata_rna[adata_rna.obs[\"split\"] == \"test\"].X\n",
    "correlation_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022_12_kaggle_ablation_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
